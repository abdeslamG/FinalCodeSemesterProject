{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter V2 Full Archive Search\n",
    "\n",
    "This document shows how to use Tweepy to conduct a full archive search using v2 of the Twitter API.\n",
    "\n",
    "## Prep work\n",
    "\n",
    "In order to use this code, you will need to have a developer account on Twitter, with access to the Academic Research product track. Information about who is eligible and how to apply is [here] OK (https://developer.twitter.com/en/products/twitter-api/academic-research).\n",
    "\n",
    "Once you have an account, you will need to create a new app at https://developer.twitter.com/en/portal/dashboard and generate a \"bearer token\" from the app. OK Copy the bearer token to your clipboard and paste it into a new file in the same directory as this file, called `twitter_authentication.py`. The entire contents of the file should look like this:\n",
    "\n",
    "```python\n",
    "bearer_token = \"YOUR BEARER TOKEN HERE\"\n",
    "```\n",
    "\n",
    "Note that you should **never** share this token with anyone else. If, for example, you are saving your work in a Git repository, make sure that you add the `twitter_authentication.py` file to your `.gitignore`.\n",
    "\n",
    "If anyone gets this token, they will have access to your Twitter account and you will need to revoke the token (from the same interface where you created it).\n",
    "\n",
    "If you've created the file successfully, then the following two blocks of code should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/abdeslamguessous/Documents/GitHub/SemesterProject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import twitter_authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAAAAAAAAAAAAAAAAAAAAHH9iAEAAAAAkMyMGd3LrN6sWA00oOgRc767oz8%3Dq1kBjW6Rq4Ksy6klsYkycODzv1g2sGdk01d2h2JtcXkk8LdNtn'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bearer_token "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token= 'AAAAAAAAAAAAAAAAAAAAAHH9iAEAAAAAkMyMGd3LrN6sWA00oOgRc767oz8%3Dq1kBjW6Rq4Ksy6klsYkycODzv1g2sGdk01d2h2JtcXkk8LdNtn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Authentication\n"
     ]
    }
   ],
   "source": [
    "# Option 1 : https://www.jcchouinard.com/how-to-use-twitter-api-with-python/ with Abdeslam credentials\n",
    "\n",
    "import tweepy\n",
    "\n",
    "api_key = \"7PwXsb3XZn4mJvX5ZiEYidVmF\"\n",
    "api_secrets = \"ySKzd5sdRrywo4LsgwWLmTcBInCXFV2nRTIsFBtPLFn3l1oDlO\"\n",
    "access_token = \"1574386671528939521-CCMs5eiKhrMOj9LLSrXbLWpLZHndKP\"\n",
    "access_secret = \"W10k6NJzUAssxfJ2Pg2rpiegur4H91iWxZh83ZHx9LHLr\"\n",
    "#access_secret = \"...\"\n",
    " \n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key,api_secrets)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    " \n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Successful Authentication')\n",
    "except:\n",
    "    print('Failed authentication')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed authentication\n"
     ]
    }
   ],
   "source": [
    "# Option 2 : https://www.jcchouinard.com/how-to-use-twitter-api-with-python/ with Aya credentials\n",
    "import tweepy\n",
    "\n",
    "api_key = \"Aa6EBqX1cbmqOnTPhG8A8TtMR\"\n",
    "api_secrets = \"4RmMu7l9TkKlT7hHCrGqDIU1LaDenCpE6XPi0EwJgI2r8F7asz\"\n",
    "access_token = \"AAAAAAAAAAAAAAAAAAAAAKcJhgEAAAAAbA54DO%2FjWW1%2Bdw%2BCBkYVkx8GgJo%3DHySsz3FJd3zucxhld6HHCr4HhSOTqKWMwaaMjMDCbNujKiDAmL\"\n",
    "access_token = \"1574384793797754881-qjVZrICjvjwp6dGnWVkLQIht0xPPw2\"\n",
    "access_secret = \"sySzUWLoDF2UrlPVmpX75Tm7UZOtzZcP6bb74dvN9KfnF\"\n",
    "#access_secret = \"...\"\n",
    " \n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key,api_secrets)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    " \n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Successful Authentication')\n",
    "except:\n",
    "    print('Failed authentication')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True) ### IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result_count': 1000, 'next_token': 'FB1SDP8CCP1HGZZZ'}\n",
      "{'result_count': 1000, 'next_token': 'B18DPCPJED11GZZZ', 'previous_token': 'HAATERI2JAUEEZZZ'}\n",
      "{'result_count': 1000, 'next_token': 'DKSK6QR66L11GZZZ', 'previous_token': '2UOMS7MRHIUUEZZZ'}\n",
      "{'result_count': 1000, 'next_token': '1IFQMI8J3L11GZZZ', 'previous_token': '46AT8H4TPAUUEZZZ'}\n",
      "{'result_count': 1000, 'next_token': '3I468EOD0T11GZZZ', 'previous_token': '718VDR7JSAUUEZZZ'}\n",
      "1589300610314158080\n",
      "1589300107014537217\n",
      "1589299603731628034\n",
      "1589299100381478919\n",
      "1589298889416445955\n",
      "1589298597044097026\n",
      "1589298093803151362\n",
      "1589297590436352000\n",
      "1589297087191171072\n",
      "1589296583765549059\n",
      "1589296080444866562\n",
      "1589295577140969473\n",
      "1589295073858027520\n",
      "1589294570554228736\n",
      "1589294067216748552\n",
      "1589293563933872128\n",
      "1589293060571238400\n",
      "1589292557279838212\n",
      "1589292053925662721\n",
      "1589291550592344067\n",
      "1589291047309529092\n",
      "1589290544001425410\n",
      "1589290040651354115\n",
      "1589289537385242626\n",
      "1589289034039414785\n",
      "1589288530706157570\n",
      "1589288027649675266\n",
      "1589287524094074890\n",
      "1589287020781879296\n",
      "1589286517465391104\n",
      "1589286014153113602\n",
      "1589285510824034304\n",
      "1589285007549468672\n",
      "1589284504157429761\n",
      "1589284000912269312\n",
      "1589283497541341186\n",
      "1589282994254127104\n",
      "1589282490954416133\n",
      "1589281987629617155\n",
      "1589281484304703488\n",
      "1589280980954652673\n",
      "1589280477659136000\n",
      "1589279974355263488\n",
      "1589279471097581572\n",
      "1589278967709712386\n",
      "1589278792920748032\n",
      "1589278464410095617\n",
      "1589277961068347392\n",
      "1589277844731199489\n",
      "1589277457760370695\n",
      "1589276954439581696\n",
      "1589276451190218752\n",
      "1589275947777277952\n",
      "1589275444502822912\n",
      "1589274941211435010\n",
      "1589274437874065408\n",
      "1589273934783864833\n",
      "1589273431241068546\n",
      "1589272927941320704\n",
      "1589272424599752704\n",
      "1589271921291665408\n",
      "1589271417979289606\n",
      "1589270914667089920\n",
      "1589270411358904324\n",
      "1589269908000591872\n",
      "1589269404700839939\n",
      "1589269370873974785\n",
      "1589268901384409088\n",
      "1589268398051151872\n",
      "1589267894726189063\n",
      "1589267391413895168\n",
      "1589266888110088192\n",
      "1589266384873263104\n",
      "1589265881502187521\n",
      "1589265378244452357\n",
      "1589264874911178752\n",
      "1589264371556950019\n",
      "1589263868328558594\n",
      "1589263364898816000\n",
      "1589262861561479168\n",
      "1589262358316294144\n",
      "1589261854966222850\n",
      "1589261351628800001\n",
      "1589260848303902722\n",
      "1589260344995749890\n",
      "1589259841742274561\n",
      "1589259338476027906\n",
      "1589258835075764225\n",
      "1589258331742511104\n",
      "1589257828446896129\n",
      "1589257325075996672\n",
      "1589256821776285696\n",
      "1589256318464016386\n",
      "1589255815512444931\n",
      "1589255311818465281\n",
      "1589254808577384450\n",
      "1589254305273495552\n",
      "1589253801885814785\n",
      "1589253298674098176\n",
      "1589252795256954881\n",
      "1589252291915309056\n",
      "1589251788712075264\n",
      "1589251285294923777\n",
      "1589250781978525697\n",
      "1589250278678749184\n",
      "1589249775341273090\n",
      "1589249272104554505\n",
      "1589248768699932673\n",
      "1589248265400340480\n",
      "1589247762067083265\n",
      "1589247258771562496\n",
      "1589246755442499585\n",
      "1589246252193046529\n",
      "1589245748788559872\n",
      "1589245245514022912\n",
      "1589244742193364995\n",
      "1589244238901936129\n",
      "1589243735610691589\n",
      "1589243232201965569\n",
      "1589242728898068482\n",
      "1589242225615069186\n",
      "1589241722294439936\n",
      "1589241325555154945\n",
      "1589241218994737158\n",
      "1589240715665612801\n",
      "1589240212319780867\n",
      "1589239709188116480\n",
      "1589239205695201283\n",
      "1589238702387200001\n",
      "1589238199053950979\n",
      "1589237695729074176\n",
      "1589237192400019458\n",
      "1589236689154805762\n",
      "1589236185779638275\n",
      "1589235682463125505\n",
      "1589235179163467776\n",
      "1589234675834388482\n",
      "1589234172555677697\n",
      "1589233669281120256\n",
      "1589233165910134784\n",
      "1589232662623014917\n",
      "1589232159277056007\n",
      "1589231655964876800\n",
      "1589231152610656257\n",
      "1589230649298354178\n",
      "1589230146006949888\n",
      "1589229642686373888\n",
      "1589229139374051329\n",
      "1589228636065906688\n",
      "1589228132736835586\n",
      "1589227629445537792\n",
      "1589227126099681280\n",
      "1589226622816862208\n",
      "1589226119462526976\n",
      "1589225616162885636\n",
      "1589225112858935297\n",
      "1589224609517297664\n",
      "1589224106226065408\n",
      "1589223602884329473\n",
      "1589223099626553346\n",
      "1589222596243083264\n",
      "1589222092922408964\n",
      "1589221589593329664\n",
      "1589221086306177026\n",
      "1589220582985441283\n",
      "1589220079664857088\n",
      "1589219576352571394\n",
      "1589219073052868609\n",
      "1589218569753092097\n",
      "1589218066398941184\n",
      "1589217563078266882\n",
      "1589217059757490180\n",
      "1589216556428451840\n",
      "1589216053124632576\n",
      "1589215549812244481\n",
      "1589215046512566285\n",
      "1589214543141543939\n",
      "1589214039841939457\n",
      "1589213536542146564\n",
      "1589213033221574656\n",
      "1589212529917657088\n",
      "1589212026601193472\n",
      "1589211523272015873\n",
      "1589211156551503874\n",
      "1589211055992934400\n",
      "1589211019947171847\n",
      "1589210998807973889\n",
      "1589210516655833090\n",
      "1589210013301710849\n",
      "1589209509997805568\n",
      "1589209006756724736\n",
      "1589208503444537345\n",
      "1589208000060874753\n",
      "1589207496752857094\n",
      "1589206993406935040\n",
      "1589206490111512577\n",
      "1589205986782363648\n",
      "1589205483491151873\n",
      "1589204980245864449\n",
      "1589204476904308737\n",
      "1589203973495463936\n",
      "1589203470225182721\n",
      "1589202966887677953\n",
      "1589202463600648192\n",
      "1589201960271577089\n",
      "1589201456959209473\n",
      "1589200953609277440\n",
      "1589200450313768960\n",
      "1589200034523815936\n",
      "1589199947009851392\n",
      "1589199443697475584\n",
      "1589198940376891394\n",
      "1589198437039411202\n",
      "1589197933735542784\n",
      "1589197430477692930\n",
      "1589196927115091968\n",
      "1589196423786012673\n",
      "1589196418773680129\n",
      "1589196327556370432\n",
      "1589195920478011392\n",
      "1589195417153150976\n",
      "1589194913895301121\n",
      "1589194410570522626\n",
      "1589194299773550592\n",
      "1589194272913625089\n",
      "1589193907178557440\n",
      "1589193403899715585\n",
      "1589192900642050049\n",
      "1589192397241696257\n",
      "1589191893933490176\n",
      "1589191390692610051\n",
      "1589190887266992128\n",
      "1589190384047083520\n",
      "1589189880692850689\n",
      "1589189377414111232\n",
      "1589188874017841153\n",
      "1589188370802135042\n",
      "1589187867393286147\n",
      "1589187364093673473\n",
      "1589186860777193474\n",
      "1589186357439651841\n",
      "1589185854228107264\n",
      "1589185350827708416\n",
      "1589184847578292227\n",
      "1589184344207269890\n",
      "1589183840874029056\n",
      "1589183337545048066\n",
      "1589182834283085825\n",
      "1589182330916278273\n",
      "1589181827750989824\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "client = tweepy.Client(bearer_token)\n",
    "for response in tweepy.Paginator(client.get_users_followers, 2244994945,\n",
    "                                    max_results=1000, limit=5):\n",
    "    print(response.meta)\n",
    "\n",
    "for tweet in tweepy.Paginator(client.search_recent_tweets, \"Tweepy\",\n",
    "                                max_results=100).flatten(limit=250):\n",
    "    print(tweet.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions Modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code is ready to use. You have simply to give your arguments (days of the month) to the main_function, then to specify on which month and year you want to work, in the dates_preprocessor function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True) ### IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time 2023-01-06 10:39:42.379120\n",
      "We are processing day  25 of November\n",
      "Dates ,  2021-11-25T00:00:00Z 2021-11-26T00:00:00Z\n",
      "4 - 0\n",
      "4 - 10\n",
      "4 - 20\n",
      "4 - 30\n",
      "4 - 40\n",
      "4 - 50\n",
      "4 - 60\n",
      "4 - 70\n",
      "4 - 80\n",
      "4 - 90\n",
      "4 - 100\n",
      "4 - 110\n",
      "4 - 120\n",
      "4 - 130\n",
      "4 - 140\n",
      "4 - 150\n",
      "4 - 160\n",
      "4 - 170\n",
      "4 - 180\n",
      "4 - 190\n",
      "We are processing day  26 of November\n",
      "Dates ,  2021-11-26T00:00:00Z 2021-11-27T00:00:00Z\n",
      "4 - 0\n",
      "4 - 10\n",
      "4 - 20\n",
      "4 - 30\n",
      "4 - 40\n",
      "4 - 50\n",
      "4 - 60\n",
      "4 - 70\n",
      "4 - 80\n",
      "4 - 90\n",
      "4 - 100\n",
      "4 - 110\n",
      "4 - 120\n",
      "4 - 130\n",
      "4 - 140\n",
      "4 - 150\n",
      "4 - 160\n",
      "4 - 170\n",
      "4 - 180\n",
      "4 - 190\n",
      "4 - 200\n",
      "4 - 210\n",
      "File Saved 11_13_59\n",
      "End Runing Time 2023-01-06 11:14:02.886618\n"
     ]
    }
   ],
   "source": [
    "output = main_function(25,26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import numpy as np \n",
    "\n",
    "def main_function(start_day, end_day):## Give numbers for example 06, 12\n",
    "    print('Start Time', datetime.now())\n",
    "    dfs =[]\n",
    "    for iterator in np.arange(start_day, end_day+1,1):\n",
    "     #   print('We are processing day ', iterator ,'of November')\n",
    "        date_start_query, date_end_query = dates_preprocessor( iterator, iterator+1)\n",
    "        tweets = run_query(date_start_query, date_end_query)\n",
    "        df = convert_dict_to_df (tweets)\n",
    "        if len(dfs)==0:\n",
    "            dfs = df\n",
    "        else:\n",
    "            dfs = dfs.append(df)\n",
    "    \n",
    "        if len(dfs)> 100000 :\n",
    "            st = datetime.now().strftime(\"%H_%M_%S\")\n",
    "            dfs.to_csv('Extractions_folder/Run_November_'+ st + 'Last_DAY:'+ str(iterator)+ '_'+ '.csv')\n",
    "            print('File Saved', st)\n",
    "            dfs = []\n",
    "    \n",
    "    print('End Runing Time', datetime.now())\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_preprocessor(start_day, end_day):\n",
    "    ## We consider that we stay in the same month.\n",
    "    iterator_start = str(start_day)\n",
    "    iterator_end = str(end_day )\n",
    "    \n",
    "    if len((iterator_start)) ==1:\n",
    "           iterator_start = '0' +iterator_start\n",
    "    if len((iterator_end)) ==1:\n",
    "           iterator_end = '0' +iterator_end\n",
    "            \n",
    "    date_start_query = '2021-11-' + iterator_start +'T00:00:00Z'\n",
    "    date_end_query =   '2021-11-' + iterator_end +'T00:00:00Z'\n",
    "\n",
    "    print('Dates , ', date_start_query, date_end_query)\n",
    "    return date_start_query, date_end_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(start_time_arg, end_time_arg):\n",
    "    btc_tweets = []\n",
    "    tmp_val = 0\n",
    "    for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = 'btc -is:retweet lang:en',\n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location',\n",
    "                                                'protected', 'entities', 'verified', 'created_at'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics',\n",
    "                                                 'possibly_sensitive', 'text', 'lang', 'reply_settings'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = start_time_arg,\n",
    "                                 end_time = end_time_arg,\n",
    "                                 max_results=499):\n",
    "        date_start_query = start_time_arg\n",
    "        date_end_query =   end_time_arg\n",
    "        if tmp_val%10 ==0 :\n",
    "            print(len(response),'-', tmp_val)\n",
    "        tmp_val+=1\n",
    "        # 3.5 \n",
    "        time.sleep(3.5)\n",
    "        btc_tweets.append(response)\n",
    "        \n",
    "    return btc_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_df (btc_tweets):\n",
    "    result = []\n",
    "    user_dict = {}\n",
    "    # Loop through each response object\n",
    "    for response in btc_tweets:\n",
    "        # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "        if 'users' in response.includes :     \n",
    "            for user in response.includes['users']:\n",
    "                user_dict[user.id] = {'username': user.username, \n",
    "                                  'followers': user.public_metrics['followers_count'],\n",
    "                                  'tweets': user.public_metrics['tweet_count'],\n",
    "                                  'following': user.public_metrics['following_count'],\n",
    "                                  'listed' :user.public_metrics['listed_count'],  \n",
    "                                  'description': user.description,\n",
    "                                  'location': user.location,\n",
    "                                  'private_account' : user.protected,\n",
    "                                  'verified_account' : user.verified,\n",
    "                                  'url': user.url,\n",
    "                                  'created_account' : user.created_at,  \n",
    "                                 }\n",
    "        for tweet in response.data:\n",
    "            # For each tweet, find the author's information\n",
    "            author_info = user_dict[tweet.author_id]\n",
    "            # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "            result.append({'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_followers': author_info['followers'],\n",
    "                       'author_tweets': author_info['tweets'],\n",
    "                        'author_following': author_info['following'],\n",
    "                       'author_listed': author_info['listed'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'author_private' : author_info['private_account'],\n",
    "                       'author_verified':author_info['verified_account'],\n",
    "                       'author_url' : author_info['url'],\n",
    "                       'author_account_creation' : author_info['created_account'],\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': tweet.created_at,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count'],\n",
    "                       'language': tweet.lang,\n",
    "                        'possibly_sensitive' :   tweet.possibly_sensitive,\n",
    "                        'reply_settings': tweet.reply_settings,\n",
    "                   #    'tweet_impression_count': tweet.non_public_metrics['impression_count'],\n",
    "                   #    'tweet_url_link_clicks': tweet.non_public_metrics['url_link_clicks'],\n",
    "                   #    'tweet_url_profile_clicks': tweet.non_public_metrics['user_profile_clicks'],      \n",
    "                     #  'promoted_like_count': tweet.organic_metrics['like_count'],\n",
    "                     #  'promoted_reply_count': tweet.organic_metrics['reply_count']\n",
    "                     #  'promoted_url_link_clicks': tweet.promoted_metrics['url_link_clicks'],\n",
    "                    #   'promoted_user_profile_clicks': tweet.promoted_metrics['user_profile_clicks']\n",
    "\n",
    "                      })\n",
    "\n",
    "    # Change this list of dictionaries into a dataframe\n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `requests`-based version - Not used\n",
    "\n",
    "If you want to do things without tweepy, here is some boilerplate code that should work. As you can see, it's much more complicated. Be grateful for the tweepy developers!! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "(403, '{\"client_id\":\"25561511\",\"detail\":\"When authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal.\",\"registration_url\":\"https://developer.twitter.com/en/docs/projects/overview\",\"title\":\"Client Forbidden\",\"required_enrollment\":\"Standard Basic\",\"reason\":\"client-not-enrolled\",\"type\":\"https://api.twitter.com/2/problems/client-forbidden\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-0beca7e699c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-0beca7e699c2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mget_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-0beca7e699c2>\u001b[0m in \u001b[0;36mget_tweets\u001b[0;34m(num_tweets, output_fh)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtweets_stored\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_tweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbearer_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnect_to_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-0beca7e699c2>\u001b[0m in \u001b[0;36mconnect_to_endpoint\u001b[0;34m(url, headers, params, next_token)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: (403, '{\"client_id\":\"25561511\",\"detail\":\"When authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal.\",\"registration_url\":\"https://developer.twitter.com/en/docs/projects/overview\",\"title\":\"Client Forbidden\",\"required_enrollment\":\"Standard Basic\",\"reason\":\"client-not-enrolled\",\"type\":\"https://api.twitter.com/2/problems/client-forbidden\"}')"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import twitter_authentication as config\n",
    "import time\n",
    "\n",
    "# Save your bearer token in a file called twitter_authentication.py in this directory\n",
    "# Should look like this:\n",
    "# bearer_token = 'YOUR_BEARER_TOKEN_HERE'\n",
    "bearer_token= bearer_token\n",
    "\n",
    "query = '(#BTC) OR (#btc)'\n",
    "out_file = 'raw_tweets.txt'\n",
    "\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "\n",
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "query_params = {'query': query,\n",
    "                'start_time': '2010-01-01T12:00:00Z',\n",
    "                'tweet.fields': 'author_id,public_metrics',\n",
    "                 'user.fields': 'username',\n",
    "                'expansions': 'author_id',\n",
    "                'max_results': 500\n",
    "               }\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    if next_token:\n",
    "        params['next_token'] = next_token\n",
    "    response = requests.request(\"GET\", search_url, headers=headers, params=params)\n",
    "    time.sleep(3.1)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_tweets(num_tweets, output_fh):\n",
    "    next_token = None\n",
    "    tweets_stored = 0\n",
    "    while tweets_stored < num_tweets:\n",
    "        headers = create_headers(bearer_token)\n",
    "        json_response = connect_to_endpoint(search_url, headers, query_params, next_token)\n",
    "        if json_response['meta']['result_count'] == 0:\n",
    "            break\n",
    "        author_dict = {x['id']: x['username'] for x in json_response['includes']['users']}\n",
    "        for tweet in json_response['data']:\n",
    "            try:\n",
    "                tweet['username'] = author_dict[tweet['author_id']]\n",
    "            except KeyError:\n",
    "                print(f\"No data for {tweet['author_id']}\")\n",
    "            output_fh.write(json.dumps(tweet) + '\\n')\n",
    "            tweets_stored += 1\n",
    "        try:\n",
    "            next_token = json_response['meta']['next_token']\n",
    "        except KeyError:\n",
    "            break\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(out_file, 'w') as f:\n",
    "        get_tweets(500, f)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "with open(out_file, 'r') as f:\n",
    "    for row in f.readlines():\n",
    "        tweet = json.loads(row)\n",
    "        tweets.append(tweet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
